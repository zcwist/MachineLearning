<!DOCTYPE html><html><head><meta charset="utf-8"><style>html { font-size: 100%; overflow-y: scroll; -webkit-text-size-adjust: 100%; -ms-text-size-adjust: 100%; }

body{
  color:#444;
  font-family:Georgia, Palatino, 'Palatino Linotype', Times, 'Times New Roman',
              "Hiragino Sans GB", "STXihei", "微软雅黑", serif;
  font-size:12px;
  line-height:1.5em;
  background:#fefefe;
  width: 45em;
  margin: 10px auto;
  padding: 1em;
  outline: 1300px solid #FAFAFA;
}

a{ color: #0645ad; text-decoration:none;}
a:visited{ color: #0b0080; }
a:hover{ color: #06e; }
a:active{ color:#faa700; }
a:focus{ outline: thin dotted; }
a:hover, a:active{ outline: 0; }

span.backtick {
  border:1px solid #EAEAEA;
  border-radius:3px;
  background:#F8F8F8;
  padding:0 3px 0 3px;
}

::-moz-selection{background:rgba(255,255,0,0.3);color:#000}
::selection{background:rgba(255,255,0,0.3);color:#000}

a::-moz-selection{background:rgba(255,255,0,0.3);color:#0645ad}
a::selection{background:rgba(255,255,0,0.3);color:#0645ad}

p{
margin:1em 0;
}

img{
max-width:100%;
}

h1,h2,h3,h4,h5,h6{
font-weight:normal;
color:#111;
line-height:1em;
}
h4,h5,h6{ font-weight: bold; }
h1{ font-size:2.5em; }
h2{ font-size:2em; border-bottom:1px solid silver; padding-bottom: 5px; }
h3{ font-size:1.5em; }
h4{ font-size:1.2em; }
h5{ font-size:1em; }
h6{ font-size:0.9em; }

blockquote{
color:#666666;
margin:0;
padding-left: 3em;
border-left: 0.5em #EEE solid;
}
hr { display: block; height: 2px; border: 0; border-top: 1px solid #aaa;border-bottom: 1px solid #eee; margin: 1em 0; padding: 0; }


pre , code, kbd, samp { 
  color: #000; 
  font-family: monospace; 
  font-size: 0.88em; 
  border-radius:3px;
  background-color: #F8F8F8;
  border: 1px solid #CCC; 
}
pre { white-space: pre; white-space: pre-wrap; word-wrap: break-word; padding: 5px 12px;}
pre code { border: 0px !important; padding: 0;}
code { padding: 0 3px 0 3px; }

b, strong { font-weight: bold; }

dfn { font-style: italic; }

ins { background: #ff9; color: #000; text-decoration: none; }

mark { background: #ff0; color: #000; font-style: italic; font-weight: bold; }

sub, sup { font-size: 75%; line-height: 0; position: relative; vertical-align: baseline; }
sup { top: -0.5em; }
sub { bottom: -0.25em; }

ul, ol { margin: 1em 0; padding: 0 0 0 2em; }
li p:last-child { margin:0 }
dd { margin: 0 0 0 2em; }

img { border: 0; -ms-interpolation-mode: bicubic; vertical-align: middle; }

table { border-collapse: collapse; border-spacing: 0; }
td { vertical-align: top; }

@media only screen and (min-width: 480px) {
body{font-size:14px;}
}

@media only screen and (min-width: 768px) {
body{font-size:16px;}
}

@media print {
  * { background: transparent !important; color: black !important; filter:none !important; -ms-filter: none !important; }
  body{font-size:12pt; max-width:100%; outline:none;}
  a, a:visited { text-decoration: underline; }
  hr { height: 1px; border:0; border-bottom:1px solid black; }
  a[href]:after { content: " (" attr(href) ")"; }
  abbr[title]:after { content: " (" attr(title) ")"; }
  .ir a:after, a[href^="javascript:"]:after, a[href^="#"]:after { content: ""; }
  pre, blockquote { border: 1px solid #999; padding-right: 1em; page-break-inside: avoid; }
  tr, img { page-break-inside: avoid; }
  img { max-width: 100% !important; }
  @page :left { margin: 15mm 20mm 15mm 10mm; }
  @page :right { margin: 15mm 10mm 15mm 20mm; }
  p, h2, h3 { orphans: 3; widows: 3; }
  h2, h3 { page-break-after: avoid; }
}
</style><title>README</title></head><body><h1 id="perceptron">Perceptron</h1>
<p>机械系 张承巍 20133102106</p>
<h2 id="_1">模块说明</h2>
<h3 id="1tfidfpy">1.Tfidf.py</h3>
<p>用于计算TF-IDF值</p>
<p>主要方法有：</p>
<h4></h4>
<p>-addDocument(signal, docName, listOfWords):导入文件</p>
<pre><code>signal:文本所属分类，在此假定baseball 是 positive，hockey 是 negative

docName:文件名称

listOfWords:被去除了标点符号的word list
</code></pre>
<p>-countTfIdf():计算在添加进的文档集合中的各文档中每个词的TF-IDF值，经过实验发现低地0.005的词都是"is" "a"等类似stop words的词，故将其排除</p>
<p>-getTfIdf():获得TfIdf值，返回值是一个List型结果，数据结构[[+/-,docName,{term: TF-IDF-value, ...}]...]</p>
<h3 id="2preprocesingpy">2.PreProcesing.py</h3>
<p>用于对文档进行前处理，导入文档，并对其进行TF-IDF的计算，生成每个文本的向量表达文本，格式为 +/- {"term":value, ...}，这样表示可以较高较地存储”文档-词“这个很稀疏的矩阵,因为我这个处理只进行一次，就采用了手工修改参数的方法</p>
<h3 id="3learningpy">3.Learning.py</h3>
<p>用于通过学习样本进行学习</p>
<h4></h4>
<p>-learnWithOut(num):学习过程采用交叉验证的方法，参数num是验证样本编号，其他文本作为学习样本。经过调试，设置alpha = 1，权值初始值 = 1，具有较好的性能。通过Rosenblatt's algorithm， 计算出学习样本中每个词的value，同样采用Dictionary形式存储，格式为{"terms":weight, ...}，收敛条件为迭代次数大于10或在样本内验证Value无误。迭代结束后，遍历一次，将value = 0的去除，因为在验证过程中:</p>
<pre><code>for feature in vector:
    p += w.get(feature, 0.0) * vector[feature]
</code></pre>
<p>计算点积，所有value = 0 的项都不会起作用，在此删除，可以有效减小W向量的规模。</p>
<p>最后输出w向量。</p>
<h3 id="4evaluationpy">4.Evaluation.py</h3>
<p>用于验证检验样本的结果</p>
<h4></h4>
<p>-evaluate(num): 以编号为num的样本作为验证样本，通过上一步中学习到的W向量，对这个样本进行验证，输出Precision, Recall, F1 Score。</p>
<h3 id="5mainpy">5.main.py</h3>
<p>依次以5个样本中的1个作为验证样本，以其他的作为学习样本，验证算法性能。</p>
<h2 id="_2">算法结果</h2>
<p>依次以1到5号样本作为验证样本，以其他的样本作为学习样本，得到如下结果:</p>
<pre><code>Learning without: No.1 Data
Err numbers:0 Iteration Times:2
Aplly to No.%d Data
Result:
precision = 0.909091
recall = 0.804020
f1 score = 0.853333
------------------
Learning without: No.2 Data
Err numbers:0 Iteration Times:4
Aplly to No.%d Data
Result:
precision = 0.982558
recall = 0.849246
f1 score = 0.911051
------------------
Learning without: No.3 Data
Err numbers:0 Iteration Times:4
Aplly to No.%d Data
Result:
precision = 0.976190
recall = 0.824121
f1 score = 0.893733
------------------
Learning without: No.4 Data
Err numbers:0 Iteration Times:4
Aplly to No.%d Data
Result:
precision = 0.977143
recall = 0.859296
f1 score = 0.914439
------------------
Learning without: No.5 Data
Err numbers:0 Iteration Times:4
Aplly to No.%d Data
Result:
precision = 0.961111
recall = 0.873737
f1 score = 0.915344
------------------
[Finished in 7.1s]
</code></pre>
<p>各项指标平均值：</p>
<pre><code>precision = 0.961219

recall = 0.842084

f1 score = 0.89758
</code></pre>
<h2 id="_3">一些问题：</h2>
<h3 id="1tf-idf">1..TF-IDF</h3>
<p>TF-IDF统计不仅依赖于单个文档，还依赖于文档所在的集合，所以定义文档集合的不同，会一定程度地影响TF-IDF值。这也带来一个问题，在算法最终应用时，必须对一个文档集进行test，也就是说，给算法一个文档集合，算法区分出其中哪些是属于Baseball，哪些是属于Hockey。 而算法并不能对单个文本进行判断，实用性较差。</p>
<h3 id="2recall">2.算法Recall值较低。</h3>
<p>从以上结果可以看出，算法的Precision值较高，可以达到0.95以上，但是Recall较低，直接拉低了F1 score，目前还没有找到问题所在和解决方案。</p></body></html>